{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Input user-item relations and user-user relations data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, embedding_dims):\n",
    "        super(Attention, self).__init__()\n",
    "        self.embed_dim = embedding_dims\n",
    "        self.att1 = nn.Linear(self.embed_dim * 2, self.embed_dim) # For joint embeddings of (x_ia, p_i)\n",
    "        self.att2 = nn.Linear(self.embed_dim, self.embed_dim)     # For reducing size of join embeddings to embed_dim\n",
    "        self.att3 = nn.Linear(self.embed_dim, 1)\n",
    "        self.softmax = nn.Softmax(0)\n",
    "\n",
    "    def forward(self, node1, u_rep, num_neighs):\n",
    "        uv_reps = u_rep.repeat(num_neighs, 1)\n",
    "        x = torch.cat((node1, uv_reps), 1)\n",
    "        x = F.relu(self.att1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.att2(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.att3(x)\n",
    "        att = F.softmax(x, dim=0)\n",
    "        return att"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "class UV_Aggregator(nn.Module):\n",
    "    \"\"\"\n",
    "    For user-item aggregations; will be used for both user latent encodings and item latent encodings\n",
    "    \"\"\"\n",
    "    def __init__(self, v2e, r2e, u2e, embed_dim, user_or_item_lists, user_or_item_ratings_lists, cuda, uv):\n",
    "        super(UV_Aggregator, self).__init__()\n",
    "        self.uv = uv\n",
    "        self.v2e = v2e\n",
    "        self.r2e = r2e\n",
    "        self.u2e = u2e\n",
    "        self.device = cuda\n",
    "        self.embed_dim = embed_dim\n",
    "        self.linear1 = nn.Linear(self.embed_dim*2, self.embed_dim) # To obtain x_ia  \n",
    "        self.linear2 = nn.Linear(self.embed_dim, self.embed_dim)   # To obtain x_ia        \n",
    "        self.att = Attention(self.embed_dim) # Add attention α∗=wT·σ(W·[x_ia ⊕ user_embeddings]+bias1)+bias2; αia = softmax(α∗) \n",
    "        # in above relation embed_dim is corresponding to user_embeddings. If not using attention, then just put 1/C(i) as att values\n",
    "        self.user_or_item_lists = user_or_item_lists\n",
    "        self.user_or_item_ratings_lists = user_or_item_ratings_lists\n",
    "        self.linear3 = nn.Linear(self.embed_dim*2, self.embed_dim)  # For Self-connections in case of neighbours social graph\n",
    "        \n",
    "    def forward(self, nodes):\n",
    "        # tmp_history_uv.append(self.user_or_item_lists[int(node)])\n",
    "        # Will also be used in case of Social Encoders\n",
    "        tmp_history_uv = []\n",
    "        tmp_history_r = []\n",
    "        for node in nodes:\n",
    "            tmp_history_uv.append(self.user_or_item_lists[int(node)])     # contains all the items rated by neighbours of user i\n",
    "            tmp_history_r.append(self.user_or_item_ratings_lists[int(node)])       # contains all the ratings of items rated by neighbours of user i\n",
    "            \n",
    "        # Aggregations Starts\n",
    "        # embed_matrix to store item aggregations of all the neighbours of user i\n",
    "        embed_matrix = torch.empty(len(tmp_history_uv), self.embed_dim, dtype=torch.float).to(self.device)        \n",
    "\n",
    "        for i in range(len(tmp_history_uv)):\n",
    "            history = tmp_history_uv[i]\n",
    "            num_histroy_item = len(history)\n",
    "            tmp_label = tmp_history_r[i]\n",
    "\n",
    "            if self.uv == True:\n",
    "                # user component for user latent embeddings\n",
    "                e_uv = self.v2e.weight[history]\n",
    "                uv_rep = self.u2e.weight[nodes[i]]\n",
    "            else:\n",
    "                # item component\n",
    "                e_uv = self.u2e.weight[history]\n",
    "                uv_rep = self.v2e.weight[nodes[i]]\n",
    "\n",
    "            e_r = self.r2e.weight[tmp_label]\n",
    "            x = torch.cat((e_uv, e_r), 1)\n",
    "            x = F.relu(self.linear1(x))\n",
    "            o_history = F.relu(self.linear2(x))     # To obtain x_ia just before applying attention\n",
    "\n",
    "            att_w = self.att(o_history, uv_rep, num_histroy_item)\n",
    "            att_history = torch.mm(o_history.t(), att_w)        #Matrix Multiplication; to calculate hi =σ(W·(summation αia*x_ia)+b)\n",
    "            att_history = att_history.t()\n",
    "\n",
    "            embed_matrix[i] = att_history                               # Item space for all neighbours\n",
    "\n",
    "        neigh_feats = embed_matrix\n",
    "        # Aggregations Ends\n",
    "\n",
    "        # For self features (u2e)\n",
    "        self_feats = self.u2e.weight[nodes]\n",
    "        # self-connection could be considered.\n",
    "        combined = torch.cat([self_feats, neigh_feats], dim=1)\n",
    "        combined = F.relu(self.linear3(combined))\n",
    "\n",
    "        return combined"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Social_Aggregator(nn.Module):\n",
    "    \"\"\"\n",
    "    Social Aggregator: for aggregating embeddings of social neighbors.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, features, u2e, embed_dim, social_adj_lists, base_model=None, cuda):\n",
    "        super(Social_Aggregator, self).__init__()\n",
    "\n",
    "        self.features = features\n",
    "        self.device = cuda\n",
    "        self.u2e = u2e\n",
    "        self.embed_dim = embed_dim\n",
    "        self.att = Attention(self.embed_dim)\n",
    "        if base_model != None:\n",
    "            self.base_model = base_model\n",
    "        self.social_adj_lists = social_adj_lists\n",
    "        self.linear1 = nn.Linear(2 * self.embed_dim, self.embed_dim) \n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, nodes):\n",
    "        embed_matrix = torch.empty(len(nodes), self.embed_dim, dtype=torch.float).to(self.device)        \n",
    "        self_feats = self.features(torch.LongTensor(nodes.cpu().numpy())).to(self.device)\n",
    "\n",
    "        to_neighs = []\n",
    "        for node in nodes:\n",
    "            to_neighs.append(self.social_adj_lists[int(node)])\n",
    "\n",
    "        neigh_feats = self.aggregator.forward(nodes, to_neighs)\n",
    "        \n",
    "        for i in range(len(nodes)):\n",
    "            tmp_adj = to_neighs[i]\n",
    "            num_neighs = len(tmp_adj)\n",
    "            # \n",
    "            e_u = self.u2e.weight[list(tmp_adj)] # fast: user embedding \n",
    "\n",
    "            u_rep = self.u2e.weight[nodes[i]]\n",
    "\n",
    "            att_w = self.att(e_u, u_rep, num_neighs)\n",
    "            att_history = torch.mm(e_u.t(), att_w).t()\n",
    "            embed_matrix[i] = att_history\n",
    "        self_feats = embed_matrix\n",
    "        self_feats = self_feats.t()\n",
    "\n",
    "\n",
    "        # self-connection could be considered.\n",
    "        combined = torch.cat([self_feats, neigh_feats], dim=1)\n",
    "        combined = F.relu(self.linear1(combined))\n",
    "        return combined"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Recommendation(nn.Module):\n",
    "    def __init__(self, enc_u, enc_v_history, r2e, embed_dim):\n",
    "        super(Recommendation, self).__init__()\n",
    "        self.enc_u = enc_u\n",
    "        self.enc_v_history = enc_v_history\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        self.w_ur1 = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.w_ur2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        \n",
    "        self.w_vr1 = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.w_vr2 = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "\n",
    "        self.w_uv1 = nn.Linear(self.embed_dim * 2, self.embed_dim)\n",
    "        self.w_uv2 = nn.Linear(self.embed_dim, 16)\n",
    "        self.w_uv3 = nn.Linear(16, 1)\n",
    "        \n",
    "        self.r2e = r2e\n",
    "        self.bn1 = nn.BatchNorm1d(self.embed_dim, momentum=0.5)\n",
    "        self.bn2 = nn.BatchNorm1d(self.embed_dim, momentum=0.5)\n",
    "        self.bn3 = nn.BatchNorm1d(self.embed_dim, momentum=0.5)\n",
    "        self.bn4 = nn.BatchNorm1d(16, momentum=0.5)\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, nodes_u, nodes_v):\n",
    "        embeds_u = self.enc_u(nodes_u)\n",
    "        embeds_v = self.enc_v_history(nodes_v)\n",
    "\n",
    "        x_u = F.relu(self.bn1(self.w_ur1(embeds_u)))\n",
    "        x_u = F.dropout(x_u, training=self.training)\n",
    "        x_u = self.w_ur2(x_u)\n",
    "        \n",
    "        x_v = F.relu(self.bn2(self.w_vr1(embeds_v)))\n",
    "        x_v = F.dropout(x_v, training=self.training)\n",
    "        x_v = self.w_vr2(x_v)\n",
    "\n",
    "        x_uv = torch.cat((x_u, x_v), 1)\n",
    "        x = F.relu(self.bn3(self.w_uv1(x_uv)))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.bn4(self.w_uv2(x)))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        scores = self.w_uv3(x)\n",
    "        return scores.squeeze()\n",
    "\n",
    "    def loss(self, nodes_u, nodes_v, labels_list):\n",
    "        scores = self.forward(nodes_u, nodes_v)\n",
    "        return self.criterion(scores, labels_list)\n",
    "\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Initialization of toy_dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "batch_size = 128\n",
    "embed_dim = 64\n",
    "lr = 0.001\n",
    "epochs = 2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_file = open(\"toy_dataset.pickle\", 'rb')\n",
    "history_u_lists, history_ur_lists, history_v_lists, history_vr_lists, train_u, train_v, train_r, test_u, test_v, test_r, social_adj_lists, ratings_list = pickle.load(data_file)\n",
    "\n",
    "\"\"\"\n",
    "## toy dataset \n",
    "history_u_lists, history_ur_lists:  user's purchased history (item set in training set), and his/her rating score (dict)\n",
    "history_v_lists, history_vr_lists:  user set who have interacted with the item, and rating score (dict)\n",
    "\n",
    "# Will be using test_u, test_v, test_r for validation purpose\n",
    "train_u, train_v, train_r: training_set (user, item, rating)\n",
    "test_u, test_v, test_r: testing set (user, item, rating)\n",
    "\n",
    "social_adj_lists: user's connected neighborhoods\n",
    "ratings_list: rating value from 0.5 to 4.0 (8 opinion embeddings)\n",
    "\"\"\"\n",
    "\n",
    "# Creating Embedding Matrix\n",
    "num_users = history_u_lists.__len__()\n",
    "num_items = history_v_lists.__len__()\n",
    "num_ratings = ratings_list.__len__()\n",
    "\n",
    "u2e = nn.Embedding(num_users, embed_dim).to(device)\n",
    "v2e = nn.Embedding(num_items, embed_dim).to(device)\n",
    "r2e = nn.Embedding(num_ratings, embed_dim).to(device)\n",
    "\n",
    "train_set = TensorDataset(torch.LongTensor(train_u), torch.LongTensor(train_v), torch.FloatTensor(train_r))\n",
    "test_set = TensorDataset(torch.LongTensor(test_u), torch.LongTensor(test_v), torch.FloatTensor(test_r))\n",
    "train_loader = DataLoader(train_set, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_set, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "# For user-item space encoding; uv=True indicates that this is for user_features\n",
    "# # User latent features\n",
    "# Item aggregations\n",
    "enc_u_history = UV_Aggregator(v2e, r2e, u2e, embed_dim, history_u_lists, history_ur_lists, cuda=device, uv=True)\n",
    "# Social Relations\n",
    "enc_u = Social_Aggregator(lambda nodes: enc_u_history(nodes).t(), u2e, embed_dim, social_adj_lists, base_model=enc_u_history, cuda=device)\n",
    "\n",
    "\n",
    "# # Item latent features\n",
    "enc_v_history = UV_Aggregator(v2e, r2e, u2e, embed_dim, history_v_lists, history_vr_lists, cuda=device, uv=False)\n",
    "\n",
    "# model\n",
    "graphrec = Recommendation(enc_u, enc_v_history, r2e, embed_dim).to(device)\n",
    "optimizer = torch.optim.RMSprop(graphrec.parameters(), lr=lr, alpha=0.9)\n",
    "\n",
    "best_mae = 9999.0\n",
    "endure_count = 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, best_rmse, best_mae):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        batch_nodes_u, batch_nodes_v, labels_list = data\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(batch_nodes_u.to(device), batch_nodes_v.to(device), labels_list.to(device))\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 0:\n",
    "            print('[%d, %5d] loss: %.3f, The best rmse/mae: %.6f' % (\n",
    "                epoch, i, running_loss / 100, best_mae))\n",
    "            running_loss = 0.0\n",
    "    return 0\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    tmp_pred = []\n",
    "    target = []\n",
    "    with torch.no_grad():\n",
    "        for test_u, test_v, tmp_target in test_loader:\n",
    "            test_u, test_v, tmp_target = test_u.to(device), test_v.to(device), tmp_target.to(device)\n",
    "            val_output = model.forward(test_u, test_v)\n",
    "            tmp_pred.append(list(val_output.data.cpu().numpy()))\n",
    "            target.append(list(tmp_target.data.cpu().numpy()))\n",
    "    tmp_pred = np.array(sum(tmp_pred, []))\n",
    "    target = np.array(sum(target, []))\n",
    "    mae = mean_absolute_error(tmp_pred, target)\n",
    "    return mae\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "\n",
    "    train(graphrec, device, train_loader, optimizer, epoch, best_rmse, best_mae)\n",
    "    expected_rmse, mae = test(graphrec, device, test_loader)\n",
    "\n",
    "    # early stopping\n",
    "    if best_rmse > expected_rmse:\n",
    "        best_rmse = expected_rmse\n",
    "        best_mae = mae\n",
    "        endure_count = 0\n",
    "    else:\n",
    "        endure_count += 1\n",
    "    print(\"rmse: %.4f, mae:%.4f \" % (expected_rmse, mae))\n",
    "\n",
    "    if endure_count > 5:\n",
    "        break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}